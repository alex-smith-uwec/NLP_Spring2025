{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/NLP_Spring2025/blob/main/Template_Medical_Questions_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28868e6f",
      "metadata": {
        "id": "28868e6f"
      },
      "source": [
        "#  NLP Assignment: Fine-Tuning a Transformer on Medical Question Pairs\n",
        "\n",
        "In this assignment, you will fine-tune a transformer model to classify whether pairs of medical questions are paraphrases of each other.\n",
        "\n",
        "Once you have everyting in place and before training, you should restart and change the runtime to TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b638748",
      "metadata": {
        "id": "3b638748"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO: set random seed to your Blugold ID\n",
        "seed=##\n",
        "##Enter your name here:"
      ],
      "metadata": {
        "id": "ajIUUTKzbh88"
      },
      "id": "ajIUUTKzbh88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "93724b3f",
      "metadata": {
        "id": "93724b3f"
      },
      "source": [
        "## Step 1: Load the Dataset\n",
        "Use the `datasets` library to load the [curaihealth medical_questions_pairs](https://huggingface.co/datasets/curaihealth/medical_questions_pairs) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2c2c7f",
      "metadata": {
        "id": "0b2c2c7f"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# TODO: Load the dataset\n",
        "\n",
        "dataset = ##\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b825eb7",
      "metadata": {
        "id": "7b825eb7"
      },
      "source": [
        "##  Train/Validation/Test Split\n",
        "The `medical_questions_pairs` dataset only provides a single training set. You need to create your own train, validation, and test sets.\n",
        "\n",
        "We'll split the dataset into:\n",
        "- **Train:** 80%\n",
        "- **Validation:** 10%\n",
        "- **Test:** 10%\n",
        "\n",
        "Use `train_test_split` from the `datasets` library to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc1d578e",
      "metadata": {
        "id": "fc1d578e"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Step 1: Split into train + temp (val + test)\n",
        "temp_split = dataset['train'].train_test_split(test_size=0.2, seed=seed)\n",
        "\n",
        "# Step 2: Split temp into validation + test (50/50 of temp = 10% each)\n",
        "val_test_split = temp_split['test'].train_test_split(test_size=0.5, seed=seed)\n",
        "\n",
        "# Step 3: Combine splits into a DatasetDict\n",
        "split_dataset = DatasetDict({\n",
        "    'train': temp_split['train'],\n",
        "    'validation': val_test_split['train'],\n",
        "    'test': val_test_split['test']\n",
        "})\n",
        "\n",
        "split_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: find an index  so that the corresponding validation question pair has label 0\n",
        "idx_0= ##\n",
        "split_dataset['validation'][idx_0]\n"
      ],
      "metadata": {
        "id": "2fftS7AGX5PC"
      },
      "id": "2fftS7AGX5PC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: find an index so that the corresponding validation question pair has label 1\n",
        "idx_1= ##\n",
        "split_dataset['validation'][idx_1]"
      ],
      "metadata": {
        "id": "_4lgIlTpZJR2"
      },
      "id": "_4lgIlTpZJR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d57071c0",
      "metadata": {
        "id": "d57071c0"
      },
      "source": [
        "## Step 2: Explore and Preprocess\n",
        "Examine the fields. Tokenize question pairs using a pretrained tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ffad30",
      "metadata": {
        "id": "f4ffad30"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        " ##Choose a model checkpoint\n",
        "checkpoint = 'microsoft/MiniLM-L12-H384-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "## Tokenization function\n",
        "def tokenize_fn(example):\n",
        "    return tokenizer(example['question_1'], example['question_2'], truncation=True, padding='max_length',max_length=256)\n",
        "\n",
        "##Apply to dataset\n",
        "tokenized = split_dataset.map(tokenize_fn, batched=True)\n",
        "tokenized"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized['train'][0])"
      ],
      "metadata": {
        "id": "Sutjbr3J2C_z"
      },
      "id": "Sutjbr3J2C_z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_question_1 = \"What are the signs of having frostbite?\"\n",
        "example_question_2 = \"What exactly is the treatment for frostbite?\"\n",
        "\n",
        "tokenized_example = tokenizer(example_question_1, example_question_2, truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "print(f\"Tokens: {tokenizer.convert_ids_to_tokens(tokenized_example['input_ids'])}\")\n"
      ],
      "metadata": {
        "id": "dA8eq9syib_u"
      },
      "id": "dA8eq9syib_u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eb087f5b",
      "metadata": {
        "id": "eb087f5b"
      },
      "source": [
        "## Step 3: Load Model\n",
        "Load a model for sequence classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a74fb3",
      "metadata": {
        "id": "54a74fb3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# TODO: Define the model from the checkpoint with correct number of labels\n",
        "model = ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3099290f",
      "metadata": {
        "id": "3099290f"
      },
      "source": [
        "## Step 4: Define Training Arguments\n",
        "Use Hugging Face `TrainingArguments` to configure training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "713acd6c",
      "metadata": {
        "id": "713acd6c"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985e83eb",
      "metadata": {
        "id": "985e83eb"
      },
      "source": [
        "## Step 5: Define Trainer\n",
        "Set up the `Trainer` object and begin training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e71ffb0",
      "metadata": {
        "id": "9e71ffb0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c00c4b79",
      "metadata": {
        "id": "c00c4b79"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "##Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized['train'],\n",
        "    eval_dataset=tokenized['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hNXLYwZXM7Ub",
      "metadata": {
        "id": "hNXLYwZXM7Ub"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20696227",
      "metadata": {
        "id": "20696227"
      },
      "source": [
        "## Step 6: Evaluation\n",
        "Evaluate and inspect results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851ff034",
      "metadata": {
        "id": "851ff034"
      },
      "outputs": [],
      "source": [
        "##Evaluate the model\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save locally first\n",
        "model.save_pretrained(\"medical-question-model\")\n",
        "tokenizer.save_pretrained(\"medical-question-model\")\n",
        "\n",
        "# Push to hub\n",
        "model.push_to_hub(\"alex-smith/medical-question-model\")\n",
        "tokenizer.push_to_hub(\"alex-smith/medical-question-model\")"
      ],
      "metadata": {
        "id": "KJwkCJpIyrQV"
      },
      "id": "KJwkCJpIyrQV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b573880c",
      "metadata": {
        "id": "b573880c"
      },
      "source": [
        "## Training Accuracy\n",
        "Now that training is complete, let's evaluate the model on the training set to report training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02493441",
      "metadata": {
        "id": "02493441"
      },
      "outputs": [],
      "source": [
        "# Evaluate on training data\n",
        "train_metrics = trainer.evaluate(tokenized[\"train\"])\n",
        "print(f\"Training Accuracy: {train_metrics['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Custom Question Pairs"
      ],
      "metadata": {
        "id": "YSFo3I0o1IB6"
      },
      "id": "YSFo3I0o1IB6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this section to test your fine-tuned model on your own question pairs. This is useful for exploring how well the model generalizes to new examples outside the training set."
      ],
      "metadata": {
        "id": "Iw0kevYQ1tNH"
      },
      "id": "Iw0kevYQ1tNH"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: replace \"your-username\" below with your huggingface user name\n",
        "model_id = \"your-username/medical-question-model\"\n"
      ],
      "metadata": {
        "id": "i16Gx-7Q2SkM"
      },
      "id": "i16Gx-7Q2SkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def evaluate_question_pair(question1, question2, model_id=model_id):\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
        "    model.eval()\n",
        "\n",
        "    # Determine max length\n",
        "    max_len = getattr(model.config, \"max_position_embeddings\", 512)\n",
        "\n",
        "    # Tokenize with explicit max_length\n",
        "    inputs = tokenizer(\n",
        "        question1, question2,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_len\n",
        "    )\n",
        "\n",
        "    # Run through model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "    predicted_class = torch.argmax(probs).item()\n",
        "    confidence = probs[0][predicted_class].item()\n",
        "    label_name = model.config.id2label.get(predicted_class, str(predicted_class))\n",
        "\n",
        "    print(f\"Q1: {question1}\")\n",
        "    print(f\"Q2: {question2}\")\n",
        "    print(f\"Predicted Label: {label_name} (Confidence: {confidence:.4f})\")\n",
        "\n",
        "    return predicted_class, confidence\n"
      ],
      "metadata": {
        "id": "VzC4OYSP2fiz"
      },
      "id": "VzC4OYSP2fiz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_question_pair(\n",
        "    \"What are the symptoms of anemia?\",\n",
        "    \"Can being tired all the time mean I have anemia?\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "BkPuKNYb0HxN"
      },
      "id": "BkPuKNYb0HxN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgiJ5Q740uHY"
      },
      "id": "sgiJ5Q740uHY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}