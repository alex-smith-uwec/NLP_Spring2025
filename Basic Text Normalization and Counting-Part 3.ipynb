{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/NLP_Spring2025/blob/main/Basic%20Text%20Normalization%20and%20Counting-Part%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14",
      "metadata": {
        "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14"
      },
      "source": [
        "\n",
        "Import corpus from Project Gutenberg\n",
        "\n",
        "Bigram analysis\n",
        "\n",
        "[ngram language model](https://en.wikipedia.org/wiki/Word_n-gram_language_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import a corpus from [Project Gutenberg](https://www.gutenberg.org/)"
      ],
      "metadata": {
        "id": "5zMjjp7nJP_p"
      },
      "id": "5zMjjp7nJP_p"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
        "outputId": "c06e390d-aef0-44bf-be3d-273eadedab28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Pride and Prejudice\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Fetch book (Plain Text UTF-8)\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\" #Jane Austen, Pride and Prejudice\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
        "outputId": "171b90f1-59f2-4baa-aa57-bdba0e31222e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first words:\n",
            " Chapter I.]\r\n",
            "\r\n",
            "\r\n",
            "It is a truth universally acknowledged, that a single man in possession\r\n",
            "of a good fortune must be in want of a wife.\r\n",
            "\r\n",
            "However little known the feelings or views of such a man may be on his\r\n",
            "first entering a neighbourhood, this truth is so well fixed in the minds\r\n",
            "of the surrounding families, that he is considered as the rightful\r\n",
            "property of some one or other of their daughters.\r\n",
            "\r\n",
            "“My dear Mr. Bennet,” said his lady to him one day, “have you heard that\r\n",
            "Netherfield Park is l\n",
            "\n",
            "\n",
            "last words:\n",
            "\n",
            "\n",
            " gratitude towards the persons who, by bringing\r\n",
            "her into Derbyshire, had been the means of uniting them.\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                                  THE\r\n",
            "                                  END\r\n",
            "                                   ]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "             CHISWICK PRESS:--CHARLES WHITTINGHAM AND CO.\r\n",
            "                  TOOKS COURT, CHANCERY LANE, LONDON.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Strip headers and footers\n",
        "start_index = text.find(\"Chapter I.]\")\n",
        "end_index = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\")\n",
        "corpus = text[start_index:end_index]\n",
        "\n",
        "# Display first 500 characters\n",
        "print(f\"first words:\\n {corpus[:500]}\\n\\n\")\n",
        "\n",
        "print(f\"last words:\\n\\n\\n {corpus[-400:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "from nltk import bigrams\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JwqbiqZO53cE"
      },
      "id": "JwqbiqZO53cE",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuEqbGo66PhY",
        "outputId": "2dff1200-c5de-4c55-ee81-acd4c472ea4b"
      },
      "id": "vuEqbGo66PhY",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the corpus into words\n",
        "words = word_tokenize(corpus.lower())\n",
        "\n",
        "# Remove punctuation\n",
        "filtered_words = [word for word in words if word.isalnum()]\n",
        "no_stop_filtered_words = [word for word in filtered_words if word not in stopwords.words('english')]"
      ],
      "metadata": {
        "id": "xQgIpXub6c-J"
      },
      "id": "xQgIpXub6c-J",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "30566891-956e-4595-88a9-c6fe072b63e7",
      "metadata": {
        "id": "30566891-956e-4595-88a9-c6fe072b63e7"
      },
      "outputs": [],
      "source": [
        "finder = BigramCollocationFinder.from_words(filtered_words)\n",
        "finder_no_stops = BigramCollocationFinder.from_words(no_stop_filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=3 #filter to bigrams that appear at least N times\n",
        "finder.apply_freq_filter(N)  # Only keep bigrams that occur at least N times\n",
        "frequent_bigrams = finder.nbest(BigramAssocMeasures.raw_freq, 20)\n",
        "\n",
        "frequent_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_k96ufbysTS",
        "outputId": "d8b18ed5-67aa-4953-f4b0-f61aff4685ca"
      },
      "id": "F_k96ufbysTS",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('of', 'the'),\n",
              " ('to', 'be'),\n",
              " ('in', 'the'),\n",
              " ('i', 'am'),\n",
              " ('of', 'her'),\n",
              " ('it', 'was'),\n",
              " ('to', 'the'),\n",
              " ('of', 'his'),\n",
              " ('she', 'was'),\n",
              " ('she', 'had'),\n",
              " ('had', 'been'),\n",
              " ('it', 'is'),\n",
              " ('i', 'have'),\n",
              " ('that', 'he'),\n",
              " ('to', 'her'),\n",
              " ('could', 'not'),\n",
              " ('for', 'the'),\n",
              " ('he', 'had'),\n",
              " ('and', 'the'),\n",
              " ('he', 'was')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=3\n",
        "finder_no_stops.apply_freq_filter(N)  # Only keep bigrams that occur at least N times\n",
        "frequent_bigrams_no_stops = finder_no_stops.nbest(BigramAssocMeasures.raw_freq, 20)\n",
        "\n",
        "frequent_bigrams_no_stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnkFzT-PmYj-",
        "outputId": "a43d8dd4-f656-444b-f231-2f1c49136772"
      },
      "id": "BnkFzT-PmYj-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lady', 'catherine'),\n",
              " ('miss', 'bingley'),\n",
              " ('miss', 'bennet'),\n",
              " ('said', 'elizabeth'),\n",
              " ('sir', 'william'),\n",
              " ('de', 'bourgh'),\n",
              " ('miss', 'darcy'),\n",
              " ('young', 'man'),\n",
              " ('1894', 'george'),\n",
              " ('colonel', 'fitzwilliam'),\n",
              " ('colonel', 'forster'),\n",
              " ('dare', 'say'),\n",
              " ('elizabeth', 'could'),\n",
              " ('young', 'ladies'),\n",
              " ('miss', 'lucas'),\n",
              " ('illustration', 'chapter'),\n",
              " ('cried', 'elizabeth'),\n",
              " ('said', 'bennet'),\n",
              " ('uncle', 'aunt'),\n",
              " ('great', 'deal')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the bigrams (1894, george) and (illustration, chapter).\n",
        "Should go back and delete these from corpus."
      ],
      "metadata": {
        "id": "s4JwA1f8hsFW"
      },
      "id": "s4JwA1f8hsFW"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict # Import Counter and defaultdict"
      ],
      "metadata": {
        "id": "W5JUmoI5iGDx"
      },
      "id": "W5JUmoI5iGDx",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "defaultdict is a subclass of Python's built-in dict class, provided by the collections module. It is used to create dictionaries that provide a default value for a key if it has not been set yet. This avoids the need to check for the existence of a key before accessing or modifying its value."
      ],
      "metadata": {
        "id": "rDPidUvOiedd"
      },
      "id": "rDPidUvOiedd"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=filtered_words #non-alpha removed, but stopwords remain"
      ],
      "metadata": {
        "id": "atF0od-Qhekn"
      },
      "id": "atF0od-Qhekn",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unigrams and bigrams\n",
        "unigram_counts = Counter(tokens)\n",
        "bigram_counts = Counter(bigrams(tokens))"
      ],
      "metadata": {
        "id": "Qdll-fhbi3Ul"
      },
      "id": "Qdll-fhbi3Ul",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bigram probabilities with Laplace smoothing\n",
        "vocab_size = len(unigram_counts)\n",
        "bigram_probs = defaultdict(lambda: 1 / vocab_size)  # Default probability for unseen bigrams\n",
        "\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_probs[(w1, w2)] = (count + 1) / (unigram_counts[w1] + vocab_size)\n",
        "\n",
        "# Test the bigram model: Probability of \"this is\"\n",
        "print(f\"P('is' | 'this') = {bigram_probs[('this', 'is')]}\")"
      ],
      "metadata": {
        "id": "nTikp1lNjDme",
        "outputId": "4008f713-7ef5-4ebe-be2d-abb07f66f7f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nTikp1lNjDme",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('is' | 'this') = 0.004526935264825713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the model\n",
        "\n",
        "def generate_bigram_text(start_word, length=20):\n",
        "    text = [start_word]\n",
        "    for _ in range(length - 1):\n",
        "        # Get all possible next words and their probabilities\n",
        "        next_word_probs = [(pair[1], prob) for pair, prob in bigram_probs.items()\n",
        "                          if pair[0] == text[-1]]\n",
        "        if not next_word_probs:\n",
        "            break\n",
        "        words, probs = zip(*next_word_probs)\n",
        "        next_word = random.choices(words, weights=probs)[0]\n",
        "        text.append(next_word)\n",
        "    return ' '.join(text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nF26DBH0737O"
      },
      "id": "nF26DBH0737O",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bigram_text('miss')"
      ],
      "metadata": {
        "id": "c_A96y2J_7NJ",
        "outputId": "9b56511e-d4b8-46c6-9910-59fae68f63be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "c_A96y2J_7NJ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'miss bennet one could provoke her perverseness he determined not watch his coming with composure everything she bore his sisters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures"
      ],
      "metadata": {
        "id": "Zcr4uqj7pLDy"
      },
      "id": "Zcr4uqj7pLDy",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenized text (example input)\n",
        "tokens=filtered_words #non-alpha removed, but stopwords remain\n",
        "\n",
        "# Create a TrigramCollocationFinder\n",
        "finder = TrigramCollocationFinder.from_words(tokens)\n",
        "\n",
        "# Apply frequency filter: only keep trigrams that occur at least N times\n",
        "N = 3  # Minimum frequency\n",
        "finder.apply_freq_filter(N)\n",
        "\n",
        "# Get the top 20 frequent trigrams based on raw frequency\n",
        "frequent_trigrams = finder.nbest(TrigramAssocMeasures.raw_freq, 20)\n",
        "\n",
        "frequent_trigrams"
      ],
      "metadata": {
        "id": "4jvrtdH7oK5A",
        "outputId": "9c145a94-455c-4453-cd9a-f44a7e926346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4jvrtdH7oK5A",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'am', 'sure'),\n",
              " ('i', 'do', 'not'),\n",
              " ('as', 'soon', 'as'),\n",
              " ('she', 'could', 'not'),\n",
              " ('i', 'can', 'not'),\n",
              " ('that', 'he', 'had'),\n",
              " ('1894', 'by', 'george'),\n",
              " ('in', 'the', 'world'),\n",
              " ('it', 'would', 'be'),\n",
              " ('it', 'was', 'not'),\n",
              " ('that', 'he', 'was'),\n",
              " ('could', 'not', 'be'),\n",
              " ('i', 'am', 'not'),\n",
              " ('that', 'it', 'was'),\n",
              " ('as', 'well', 'as'),\n",
              " ('i', 'dare', 'say'),\n",
              " ('would', 'have', 'been'),\n",
              " ('by', 'no', 'means'),\n",
              " ('can', 'not', 'be'),\n",
              " ('that', 'she', 'had')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozN7cVb0pJk-"
      },
      "id": "ozN7cVb0pJk-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnO8mfiQowFk"
      },
      "id": "MnO8mfiQowFk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unigrams, bigrams, and trigrams\n",
        "unigram_counts = Counter(tokens)\n",
        "bigram_counts = Counter(bigrams(tokens))\n",
        "trigram_counts = Counter(zip(tokens[:-2], tokens[1:-1], tokens[2:]))\n",
        "\n"
      ],
      "metadata": {
        "id": "OdEvydblkMqx"
      },
      "id": "OdEvydblkMqx",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate trigram probabilities with Laplace smoothing\n",
        "vocab_size = len(unigram_counts)\n",
        "trigram_probs = defaultdict(lambda: 1 / vocab_size)  # Default probability for unseen trigrams\n",
        "\n",
        "for (w1, w2, w3), count in trigram_counts.items():\n",
        "    trigram_probs[(w1, w2, w3)] = (count + 1) / (bigram_counts[(w1, w2)] + vocab_size)\n",
        "\n",
        "# Test the trigram model: Probability of \"am sure\" given \"i\"\n",
        "print(f\"P('sure' | 'i am') = {trigram_probs[('i', 'am', 'sure')]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RbVDAvzknrM8",
        "outputId": "8be14ce6-4abd-4557-df62-1c9ec0f8c5dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RbVDAvzknrM8",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('sure' | 'i am') = 0.009545804464973056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the trigram model\n",
        "def generate_trigram_text(start_words, length=20):\n",
        "    # `start_words` should contain two words to start the trigram model\n",
        "    if len(start_words) != 2:\n",
        "        raise ValueError(\"start_words must contain exactly two words.\")\n",
        "\n",
        "    text = list(start_words)\n",
        "    for _ in range(length - 2):\n",
        "        # Get all possible next words and their probabilities\n",
        "        next_word_probs = [\n",
        "            (triple[2], prob) for triple, prob in trigram_probs.items()\n",
        "            if triple[0] == text[-2] and triple[1] == text[-1]\n",
        "        ]\n",
        "        if not next_word_probs:\n",
        "            break\n",
        "        words, probs = zip(*next_word_probs)\n",
        "        next_word = random.choices(words, weights=probs)[0]\n",
        "        text.append(next_word)\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "bFwWgPxHnrqM"
      },
      "id": "bFwWgPxHnrqM",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_trigram_text(start_words=('i','am'),length=20)"
      ],
      "metadata": {
        "id": "ZLk0Z7q_nsGa",
        "outputId": "fe2ba5fa-498e-430f-ad2d-4fe4084f02e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "ZLk0Z7q_nsGa",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am her particular friend you see by jane had read the note aloud if your mother of inviting as'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akKizTQWqGUQ"
      },
      "id": "akKizTQWqGUQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}