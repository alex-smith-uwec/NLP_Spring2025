{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/NLP_Spring2025/blob/main/Basic%20Text%20Normalization%20and%20Counting-Part%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14",
      "metadata": {
        "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14"
      },
      "source": [
        "\n",
        "Import corpus from Project Gutenberg\n",
        "\n",
        "Bigram analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import a corpus from [Project Gutenberg](https://www.gutenberg.org/)"
      ],
      "metadata": {
        "id": "5zMjjp7nJP_p"
      },
      "id": "5zMjjp7nJP_p"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
        "outputId": "897defef-db85-4b1f-97f6-3816f3b73ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Pride and Prejudice\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Fetch book (Plain Text UTF-8)\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\" #Jane Austen, Pride and Prejudice\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
        "outputId": "2786812e-c1f2-48ca-80f3-f615012e0887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first words:\n",
            " Chapter I.]\r\n",
            "\r\n",
            "\r\n",
            "It is a truth universally acknowledged, that a single man in possession\r\n",
            "of a good fortune must be in want of a wife.\r\n",
            "\r\n",
            "However little known the feelings or views of such a man may be on his\r\n",
            "first entering a neighbourhood, this truth is so well fixed in the minds\r\n",
            "of the surrounding families, that he is considered as the rightful\r\n",
            "property of some one or other of their daughters.\r\n",
            "\r\n",
            "“My dear Mr. Bennet,” said his lady to him one day, “have you heard that\r\n",
            "Netherfield Park is l\n",
            "\n",
            "\n",
            "last words:\n",
            "\n",
            "\n",
            " gratitude towards the persons who, by bringing\r\n",
            "her into Derbyshire, had been the means of uniting them.\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                                  THE\r\n",
            "                                  END\r\n",
            "                                   ]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "             CHISWICK PRESS:--CHARLES WHITTINGHAM AND CO.\r\n",
            "                  TOOKS COURT, CHANCERY LANE, LONDON.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Strip headers and footers\n",
        "start_index = text.find(\"Chapter I.]\")\n",
        "end_index = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\")\n",
        "corpus = text[start_index:end_index]\n",
        "\n",
        "# Display first 500 characters\n",
        "print(f\"first words:\\n {corpus[:500]}\\n\\n\")\n",
        "\n",
        "print(f\"last words:\\n\\n\\n {corpus[-400:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "from nltk import bigrams\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JwqbiqZO53cE"
      },
      "id": "JwqbiqZO53cE",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuEqbGo66PhY",
        "outputId": "9832e9cc-74a0-45d8-ef4a-25aaf1222900"
      },
      "id": "vuEqbGo66PhY",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the corpus into words\n",
        "words = word_tokenize(corpus.lower())\n",
        "\n",
        "# Remove punctuation\n",
        "filtered_words = [word for word in words if word.isalnum()]\n"
      ],
      "metadata": {
        "id": "xQgIpXub6c-J"
      },
      "id": "xQgIpXub6c-J",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "30566891-956e-4595-88a9-c6fe072b63e7",
      "metadata": {
        "id": "30566891-956e-4595-88a9-c6fe072b63e7"
      },
      "outputs": [],
      "source": [
        "finder = BigramCollocationFinder.from_words(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=3 #filter to bigrams that appear at least N times\n",
        "finder.apply_freq_filter(N)  # Only keep bigrams that occur at least N times\n",
        "frequent_bigrams = finder.nbest(BigramAssocMeasures.raw_freq, 20)\n",
        "\n",
        "frequent_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_k96ufbysTS",
        "outputId": "ea4bb366-590b-416c-a15e-1b9493907c1a"
      },
      "id": "F_k96ufbysTS",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('of', 'the'),\n",
              " ('to', 'be'),\n",
              " ('in', 'the'),\n",
              " ('i', 'am'),\n",
              " ('of', 'her'),\n",
              " ('it', 'was'),\n",
              " ('to', 'the'),\n",
              " ('of', 'his'),\n",
              " ('she', 'was'),\n",
              " ('she', 'had'),\n",
              " ('had', 'been'),\n",
              " ('it', 'is'),\n",
              " ('i', 'have'),\n",
              " ('that', 'he'),\n",
              " ('to', 'her'),\n",
              " ('could', 'not'),\n",
              " ('for', 'the'),\n",
              " ('he', 'had'),\n",
              " ('and', 'the'),\n",
              " ('he', 'was')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model(cfdist, word, num=15):\n",
        "    for i in range(num):\n",
        "        print(word, end=' ')\n",
        "        # Get the most frequent next words (up to 3)\n",
        "        next_words = list(cfdist[word].keys())[:3]\n",
        "        if next_words:\n",
        "            # Randomly choose from the top 3 words\n",
        "            word = random.choice(next_words)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "\n",
        "# Generate bigrams from your list of words\n",
        "filtered_bigrams = bigrams(filtered_words)\n",
        "\n",
        "# Create a Conditional Frequency Distribution (CFD) from these bigrams\n",
        "cfd = ConditionalFreqDist(filtered_bigrams)\n",
        "\n",
        "# Example usage\n",
        "generate_model(cfd, 'sir')  # Replace 'your_seed_word' with your desired starting word\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAeBQeEe7jM2",
        "outputId": "b3bd5bb8-5d6f-4582-8990-d9bfe93ceccc"
      },
      "id": "yAeBQeEe7jM2",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sir william lucas her own in possession and i it cried he is a single "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict # Import Counter and defaultdict\n",
        "\n",
        "\n",
        "tokens=filtered_words\n",
        "\n",
        "# Count unigrams and bigrams\n",
        "unigram_counts = Counter(tokens)\n",
        "bigram_counts = Counter(bigrams(tokens))\n",
        "\n",
        "# Calculate bigram probabilities with Laplace smoothing\n",
        "vocab_size = len(unigram_counts)\n",
        "bigram_probs = defaultdict(lambda: 1 / vocab_size)  # Default probability for unseen bigrams\n",
        "\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_probs[(w1, w2)] = (count + 1) / (unigram_counts[w1] + vocab_size)\n",
        "\n",
        "# Test the bigram model: Probability of \"this is\"\n",
        "print(f\"P('is' | 'this') = {bigram_probs[('this', 'is')]}\")\n",
        "\n",
        "# Generate text using the model\n",
        "import random\n",
        "\n",
        "def generate_bigram_text(start_word, length=20):\n",
        "    text = [start_word]\n",
        "    for _ in range(length - 1):\n",
        "        next_words = [pair[1] for pair in bigram_probs if pair[0] == text[-1]]\n",
        "        if not next_words:  # No valid next word\n",
        "            break\n",
        "        next_word = random.choice(next_words)\n",
        "        text.append(next_word)\n",
        "    return ' '.join(text)\n",
        "\n",
        "print(\"Generated Text:\", generate_bigram_text('this'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF26DBH0737O",
        "outputId": "8b6e4dc7-18e7-4b01-b9a5-e35810ee1535"
      },
      "id": "nF26DBH0737O",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('is' | 'this') = 0.004526935264825713\n",
            "Generated Text: this remark but affability and gentlemanlike those weaknesses which almost say three ladies removed to dance for basis the their\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdEvydblkMqx"
      },
      "id": "OdEvydblkMqx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}