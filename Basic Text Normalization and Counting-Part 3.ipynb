{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/NLP_Spring2025/blob/main/Basic%20Text%20Normalization%20and%20Counting-Part%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14",
      "metadata": {
        "id": "6113f911-bc6f-44e0-b733-79aa64f8ff14"
      },
      "source": [
        "\n",
        "Import corpus from Project Gutenberg\n",
        "\n",
        "Bigram and trigram analysis\n",
        "\n",
        "[ngram language model](https://en.wikipedia.org/wiki/Word_n-gram_language_model)\n",
        "\n",
        "[Google Books Ngram Viewer](https://books.google.com/ngrams/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import a corpus from [Project Gutenberg](https://www.gutenberg.org/)"
      ],
      "metadata": {
        "id": "5zMjjp7nJP_p"
      },
      "id": "5zMjjp7nJP_p"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6569c9-06df-4bf4-9ad3-8cffbe60975c",
        "outputId": "57443ef9-3c80-4b20-9c02-36898d38d328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Pride and Prejudice\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Fetch book (Plain Text UTF-8)\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\" #Jane Austen, Pride and Prejudice\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f2d93c-31ac-46fd-b38e-aa4c918ef725",
        "outputId": "64b860b6-2ce5-491a-80e4-c98716ce3f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first words:\n",
            " Chapter I.]\r\n",
            "\r\n",
            "\r\n",
            "It is a truth universally acknowledged, that a single man in possession\r\n",
            "of a good fortune must be in want of a wife.\r\n",
            "\r\n",
            "However little known the feelings or views of such a man may be on his\r\n",
            "first entering a neighbourhood, this truth is so well fixed in the minds\r\n",
            "of the surrounding families, that he is considered as the rightful\r\n",
            "property of some one or other of their daughters.\r\n",
            "\r\n",
            "“My dear Mr. Bennet,” said his lady to him one day, “have you heard that\r\n",
            "Netherfield Park is l\n",
            "\n",
            "\n",
            "last words:\n",
            "\n",
            "\n",
            " gratitude towards the persons who, by bringing\r\n",
            "her into Derbyshire, had been the means of uniting them.\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                                  THE\r\n",
            "                                  END\r\n",
            "                                   ]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "             CHISWICK PRESS:--CHARLES WHITTINGHAM AND CO.\r\n",
            "                  TOOKS COURT, CHANCERY LANE, LONDON.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Strip headers and footers\n",
        "start_index = text.find(\"Chapter I.]\")\n",
        "end_index = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\")\n",
        "corpus = text[start_index:end_index]\n",
        "\n",
        "# Display first 500 characters\n",
        "print(f\"first words:\\n {corpus[:500]}\\n\\n\")\n",
        "\n",
        "print(f\"last words:\\n\\n\\n {corpus[-400:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation: NLTK tools and tokenizing corpus"
      ],
      "metadata": {
        "id": "kef2yvjcwd5O"
      },
      "id": "kef2yvjcwd5O"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions -q"
      ],
      "metadata": {
        "id": "5M0wpkxrPdPn",
        "outputId": "dc69f1e9-59d7-492d-bf93-8244413ef359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5M0wpkxrPdPn",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/289.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/289.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/110.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import bigrams\n",
        "\n",
        "\n",
        "import contractions\n",
        "\n",
        "\n",
        "\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n",
        "\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "from nltk.metrics import TrigramAssocMeasures\n",
        "\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JwqbiqZO53cE"
      },
      "id": "JwqbiqZO53cE",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand contractions and replace possesive 's with just s.\n",
        "def clean_text(text):\n",
        "    # Expand contractions\n",
        "    expanded_text = contractions.fix(text)\n",
        "\n",
        "    # Replace remaining possessive 's with s\n",
        "    cleaned_text = expanded_text.replace(\"'s\", \"s\")\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "mRjplOTfPCEK"
      },
      "id": "mRjplOTfPCEK",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = clean_text(corpus)"
      ],
      "metadata": {
        "id": "UQHnH8xUPxYM"
      },
      "id": "UQHnH8xUPxYM",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuEqbGo66PhY",
        "outputId": "50163f1c-f2f0-4601-841f-f04f8e30f7d4"
      },
      "id": "vuEqbGo66PhY",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare two lists of words.\n",
        "One list has all words, with punctuation removed.\n",
        "The other list furthermore removes stopwords.\n",
        "\n",
        "These lists are named **filtered_words** and **no_stop_filtered_words**"
      ],
      "metadata": {
        "id": "tfFAoUn3w2C3"
      },
      "id": "tfFAoUn3w2C3"
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the corpus into words\n",
        "words = word_tokenize(corpus.lower())\n",
        "\n",
        "\n",
        "# Remove punctuation\n",
        "filtered_words = [word for word in words if word.isalnum()]\n",
        "\n",
        "#Remove stopwords\n",
        "no_stop_filtered_words = [word for word in filtered_words if word not in stopwords.words('english')]"
      ],
      "metadata": {
        "id": "xQgIpXub6c-J"
      },
      "id": "xQgIpXub6c-J",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##After reviewing bigrams (below), decision to delete\n",
        "#1894, george,illustration, chapter\n",
        "\n",
        "# filtered_words = [word for word in filtered_words if word not in ['1894', 'george', 'illustration', 'chapter']]\n",
        "# no_stop_filtered_words = [word for word in filtered_words if word not in stopwords.words('english')]"
      ],
      "metadata": {
        "id": "NUSABGF4HnSM"
      },
      "id": "NUSABGF4HnSM",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigram model"
      ],
      "metadata": {
        "id": "D2xiw0L5sn-H"
      },
      "id": "D2xiw0L5sn-H"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "30566891-956e-4595-88a9-c6fe072b63e7",
      "metadata": {
        "id": "30566891-956e-4595-88a9-c6fe072b63e7"
      },
      "outputs": [],
      "source": [
        "finder = BigramCollocationFinder.from_words(filtered_words)\n",
        "finder_no_stops = BigramCollocationFinder.from_words(no_stop_filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=3 #filter to bigrams that appear at least N times\n",
        "finder.apply_freq_filter(N)  # Only keep bigrams that occur at least N times\n",
        "frequent_bigrams = finder.nbest(BigramAssocMeasures.raw_freq, 25)\n",
        "\n",
        "frequent_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_k96ufbysTS",
        "outputId": "c7e9e54d-060d-44be-8854-976887bf9f80"
      },
      "id": "F_k96ufbysTS",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('of', 'the'),\n",
              " ('to', 'be'),\n",
              " ('in', 'the'),\n",
              " ('i', 'am'),\n",
              " ('of', 'her'),\n",
              " ('it', 'was'),\n",
              " ('to', 'the'),\n",
              " ('of', 'his'),\n",
              " ('she', 'was'),\n",
              " ('she', 'had'),\n",
              " ('had', 'been'),\n",
              " ('it', 'is'),\n",
              " ('i', 'have'),\n",
              " ('that', 'he'),\n",
              " ('to', 'her'),\n",
              " ('could', 'not'),\n",
              " ('for', 'the'),\n",
              " ('he', 'had'),\n",
              " ('and', 'the'),\n",
              " ('he', 'was'),\n",
              " ('on', 'the'),\n",
              " ('such', 'a'),\n",
              " ('in', 'a'),\n",
              " ('have', 'been'),\n",
              " ('did', 'not')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=3\n",
        "finder_no_stops.apply_freq_filter(N)  # Only keep bigrams that occur at least N times\n",
        "frequent_bigrams_no_stops = finder_no_stops.nbest(BigramAssocMeasures.raw_freq, 20)\n",
        "\n",
        "frequent_bigrams_no_stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnkFzT-PmYj-",
        "outputId": "be64a349-eb07-4e6b-9de9-d396c8639e41"
      },
      "id": "BnkFzT-PmYj-",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lady', 'catherine'),\n",
              " ('miss', 'bingley'),\n",
              " ('miss', 'bennet'),\n",
              " ('said', 'elizabeth'),\n",
              " ('sir', 'william'),\n",
              " ('de', 'bourgh'),\n",
              " ('miss', 'darcy'),\n",
              " ('young', 'man'),\n",
              " ('1894', 'george'),\n",
              " ('colonel', 'fitzwilliam'),\n",
              " ('colonel', 'forster'),\n",
              " ('dare', 'say'),\n",
              " ('elizabeth', 'could'),\n",
              " ('young', 'ladies'),\n",
              " ('miss', 'lucas'),\n",
              " ('illustration', 'chapter'),\n",
              " ('cried', 'elizabeth'),\n",
              " ('said', 'bennet'),\n",
              " ('uncle', 'aunt'),\n",
              " ('great', 'deal')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the bigrams (1894, george) and (illustration, chapter).\n",
        "Should go back and delete these from corpus."
      ],
      "metadata": {
        "id": "s4JwA1f8hsFW"
      },
      "id": "s4JwA1f8hsFW"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict # Import Counter and defaultdict"
      ],
      "metadata": {
        "id": "W5JUmoI5iGDx"
      },
      "id": "W5JUmoI5iGDx",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defaultdict** is a subclass of Python's built-in dict class, provided by the collections module. It is used to create dictionaries that provide a default value for a key if it has not been set yet. This avoids the need to check for the existence of a key before accessing or modifying its value."
      ],
      "metadata": {
        "id": "rDPidUvOiedd"
      },
      "id": "rDPidUvOiedd"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=filtered_words #non-alpha removed, but stopwords remain"
      ],
      "metadata": {
        "id": "atF0od-Qhekn"
      },
      "id": "atF0od-Qhekn",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unigrams and bigrams\n",
        "unigram_counts = Counter(tokens)\n",
        "bigram_counts = Counter(bigrams(tokens))"
      ],
      "metadata": {
        "id": "Qdll-fhbi3Ul"
      },
      "id": "Qdll-fhbi3Ul",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bigram probabilities with Laplace smoothing\n",
        "vocab_size = len(unigram_counts)\n",
        "bigram_probs = defaultdict(lambda: 1 / vocab_size)  # Default probability for unseen bigrams\n",
        "\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_probs[(w1, w2)] = (count + 1) / (unigram_counts[w1] + vocab_size)\n",
        "\n",
        "# Test the bigram model: Probability of \"this is\"\n",
        "print(f\"P('is' | 'this') = {bigram_probs[('this', 'is')]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTikp1lNjDme",
        "outputId": "357d32ed-c6a7-4aba-fd49-3f05e231ee02"
      },
      "id": "nTikp1lNjDme",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('is' | 'this') = 0.004532406707961928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the model\n",
        "\n",
        "def generate_bigram_text(start_word, length=20):\n",
        "    text = [start_word]\n",
        "    for _ in range(length - 1):\n",
        "        # Get all possible next words and their probabilities\n",
        "        next_word_probs = [(pair[1], prob) for pair, prob in bigram_probs.items()\n",
        "                          if pair[0] == text[-1]]\n",
        "        if not next_word_probs:\n",
        "            break\n",
        "        words, probs = zip(*next_word_probs)\n",
        "        next_word = random.choices(words, weights=probs)[0]\n",
        "        text.append(next_word)\n",
        "    return ' '.join(text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nF26DBH0737O"
      },
      "id": "nF26DBH0737O",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bigram_text('miss')"
      ],
      "metadata": {
        "id": "c_A96y2J_7NJ",
        "outputId": "7e457375-a49b-456c-ec9a-aa93ecedd68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "c_A96y2J_7NJ",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'miss king there is eat and darcy elizabeth took leave it has too early and so exceedingly angry people his'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLnU1-WgsPQj"
      },
      "id": "eLnU1-WgsPQj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigram model"
      ],
      "metadata": {
        "id": "4wnGTGoqs1S7"
      },
      "id": "4wnGTGoqs1S7"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxktXWfJsNxN"
      },
      "id": "oxktXWfJsNxN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "P(w_3 \\mid w_1, w_2) = \\frac{\\text{count}(w_1, w_2, w_3) + 1}{\\text{count}(w_1, w_2) + V}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "YeaQjJZ0r5h8"
      },
      "id": "YeaQjJZ0r5h8"
    },
    {
      "cell_type": "code",
      "source": [
        "finder3 = TrigramCollocationFinder.from_words(filtered_words)\n",
        "finder3_no_stops = TrigramCollocationFinder.from_words(no_stop_filtered_words)"
      ],
      "metadata": {
        "id": "2SMmo2SvJEP2"
      },
      "id": "2SMmo2SvJEP2",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N=2 #filter to trigrams that appear at least N times\n",
        "finder3.apply_freq_filter(N)  # Only keep trigrams that occur at least N times\n",
        "frequent_trigrams = finder3.nbest(TrigramAssocMeasures.raw_freq, 25)\n",
        "\n",
        "frequent_trigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNOgn9hRKNZd",
        "outputId": "344c8059-71eb-476d-a7cc-f539003c8e9f"
      },
      "id": "RNOgn9hRKNZd",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'am', 'sure'),\n",
              " ('i', 'do', 'not'),\n",
              " ('as', 'soon', 'as'),\n",
              " ('i', 'can', 'not'),\n",
              " ('she', 'could', 'not'),\n",
              " ('that', 'he', 'had'),\n",
              " ('1894', 'by', 'george'),\n",
              " ('in', 'the', 'world'),\n",
              " ('it', 'would', 'be'),\n",
              " ('it', 'was', 'not'),\n",
              " ('that', 'he', 'was'),\n",
              " ('could', 'not', 'be'),\n",
              " ('i', 'am', 'not'),\n",
              " ('that', 'it', 'was'),\n",
              " ('as', 'well', 'as'),\n",
              " ('i', 'dare', 'say'),\n",
              " ('would', 'have', 'been'),\n",
              " ('by', 'no', 'means'),\n",
              " ('can', 'not', 'be'),\n",
              " ('that', 'she', 'had'),\n",
              " ('and', 'she', 'was'),\n",
              " ('on', 'the', 'subject'),\n",
              " ('one', 'of', 'the'),\n",
              " ('he', 'had', 'been'),\n",
              " ('i', 'did', 'not')]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=2 #filter to trigrams that appear at least N times\n",
        "finder3_no_stops.apply_freq_filter(N)  # Only keep trigrams that occur at least N times\n",
        "frequent_trigrams_no_stops = finder3_no_stops.nbest(TrigramAssocMeasures.raw_freq, 25)\n",
        "\n",
        "frequent_trigrams_no_stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEfdpIKVJEmw",
        "outputId": "0be1de67-ed56-41d6-da51-299e51b8163c"
      },
      "id": "HEfdpIKVJEmw",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('miss', 'de', 'bourgh'),\n",
              " ('lady', 'catherine', 'de'),\n",
              " ('1894', 'george', 'chapter'),\n",
              " ('catherine', 'de', 'bourgh'),\n",
              " ('said', 'miss', 'bingley'),\n",
              " ('sir', 'william', 'lucas'),\n",
              " ('hurst', 'miss', 'bingley'),\n",
              " ('lady', 'catherine', 'daughter'),\n",
              " ('ten', 'thousand', 'pounds'),\n",
              " ('could', 'think', 'nothing'),\n",
              " ('could', 'think', 'without'),\n",
              " ('dear', 'said', 'bennet'),\n",
              " ('elizabeth', 'could', 'help'),\n",
              " ('elizabeth', 'made', 'answer'),\n",
              " ('lady', 'catherine', 'seemed'),\n",
              " ('may', 'depend', 'upon'),\n",
              " ('miss', 'bennet', 'came'),\n",
              " ('miss', 'elizabeth', 'bennet'),\n",
              " ('said', 'elizabeth', 'must'),\n",
              " ('since', 'went', 'away'),\n",
              " ('ten', 'thousand', 'year'),\n",
              " ('three', 'young', 'ladies'),\n",
              " ('without', 'saying', 'word'),\n",
              " ('card', 'tables', 'placed'),\n",
              " ('could', 'hardly', 'help')]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unigrams, bigrams, and trigrams\n",
        "unigram_counts = Counter(tokens)\n",
        "bigram_counts = Counter(bigrams(tokens))\n",
        "trigram_counts = Counter(zip(tokens[:-2], tokens[1:-1], tokens[2:]))\n",
        "\n"
      ],
      "metadata": {
        "id": "OdEvydblkMqx"
      },
      "id": "OdEvydblkMqx",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate trigram probabilities with Laplace smoothing\n",
        "vocab_size = len(unigram_counts)\n",
        "trigram_probs = defaultdict(lambda: 1 / vocab_size)  # Default probability for unseen trigrams\n",
        "\n",
        "for (w1, w2, w3), count in trigram_counts.items():\n",
        "    trigram_probs[(w1, w2, w3)] = (count + 1) / (bigram_counts[(w1, w2)] + vocab_size)\n",
        "\n",
        "# Test the trigram model: Probability of \"am sure\" given \"i\"\n",
        "print(f\"P('sure' | 'i am') = {trigram_probs[('i', 'am', 'sure')]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVDAvzknrM8",
        "outputId": "43ccdaa3-33fe-477c-ee9b-1eb672acc810"
      },
      "id": "RbVDAvzknrM8",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('sure' | 'i am') = 0.009554630913854214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the trigram model\n",
        "def generate_trigram_text(start_words, length=20):\n",
        "    # `start_words` should contain two words to start the trigram model\n",
        "    if len(start_words) != 2:\n",
        "        raise ValueError(\"start_words must contain exactly two words.\")\n",
        "\n",
        "    text = list(start_words)\n",
        "    for _ in range(length - 2):\n",
        "        # Get all possible next words and their probabilities\n",
        "        next_word_probs = [\n",
        "            (triple[2], prob) for triple, prob in trigram_probs.items()\n",
        "            if triple[0] == text[-2] and triple[1] == text[-1]\n",
        "        ]\n",
        "        if not next_word_probs:\n",
        "            break\n",
        "        words, probs = zip(*next_word_probs)\n",
        "        next_word = random.choices(words, weights=probs)[0]\n",
        "        text.append(next_word)\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "bFwWgPxHnrqM"
      },
      "id": "bFwWgPxHnrqM",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_trigram_text(start_words=('i','am'),length=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZLk0Z7q_nsGa",
        "outputId": "c5976415-0217-4cf5-8da3-247e33643997"
      },
      "id": "ZLk0Z7q_nsGa",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am not certain that the experience of years had been always at elizabeth looked expressively at lydia but while'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akKizTQWqGUQ"
      },
      "id": "akKizTQWqGUQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}