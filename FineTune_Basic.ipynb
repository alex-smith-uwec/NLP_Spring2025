{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-smith-uwec/NLP_Spring2025/blob/main/FineTune_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#If you plan to get actually get to the fine tuning stage at the bottom of this notebook, then before you begin you should change the runtime to GPU. If you are just noodling around with stuff before that, then just leave things with CPU."
      ],
      "metadata": {
        "id": "NCHhmWhPM0Te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content of this notebook is adapted from the video below by Lewis Tunstall.\n"
      ],
      "metadata": {
        "id": "YR6oG0UiQFJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/u--UVvH-LIQ?si=EqRlGOizWG7tgF7b\" frameborder=\"0\" allowfullscreen></iframe>')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qMgyMxPYSLB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qQ1zAGfWplV"
      },
      "outputs": [],
      "source": [
        "# !pip install 'accelerate>=0.21.0' -U -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f8s-xbeWrtj"
      },
      "outputs": [],
      "source": [
        "!pip install 'transformers[torch]' -U -q\n",
        "# !pip install 'transformers[tensorflow]'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "id": "vZVNm7eQ1oUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0IENzy9YL1p"
      },
      "outputs": [],
      "source": [
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayCCtCMqZ7QX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q8Oxo5CWr1b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Emotion Dataset"
      ],
      "metadata": {
        "id": "0-6hlpAaPjO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " [The emotion dataset](https://huggingface.co/datasets/dair-ai/emotion)\n",
        " dataset card on huggingface"
      ],
      "metadata": {
        "id": "M8LNj_U_PYp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqPtGyxnu_LD"
      },
      "outputs": [],
      "source": [
        "emotion_dataset=load_dataset(\"emotion\",trust_remote_code=True)\n",
        "emotion_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mz-_QOSxLXC"
      },
      "outputs": [],
      "source": [
        "random_integer = random.randint(0, 16000)\n",
        "random_integer\n",
        "\n",
        "emotion_dataset[\"train\"][random_integer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXJj4wYWyYTK"
      },
      "outputs": [],
      "source": [
        "emotion_df=emotion_dataset[\"train\"].to_pandas()\n",
        "emotion_df[10:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIyeqUE2zMtp"
      },
      "outputs": [],
      "source": [
        "features=emotion_dataset[\"train\"].features\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdwvTjfQ1mHL"
      },
      "outputs": [],
      "source": [
        "features[\"label\"].int2str(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOc_ALHf2gFB"
      },
      "outputs": [],
      "source": [
        "id2label={idx:features[\"label\"].int2str(idx) for idx in range(6)}\n",
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAqmffdX23zN"
      },
      "outputs": [],
      "source": [
        "label2id={v:k for k,v in id2label.items()}\n",
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc_oY1NG4H-B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ6nb9xn3RT8"
      },
      "outputs": [],
      "source": [
        "emotion_df[\"label\"].value_counts(normalize=True).sort_index()\n",
        "#See 5:32 minute mark: distribution of values is very uneven!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sklearn F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
        "\n",
        "For evaluation of the model, we will use an F-score, which is often used for imbalanced situtations."
      ],
      "metadata": {
        "id": "hbs3HAGX42dF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbmOVbO74mD-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENpiHX0Y5X9l"
      },
      "source": [
        "#Tokenize everything"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model checkpoint [huggingface card](https://huggingface.co/microsoft/MiniLM-L12-H384-uncased)"
      ],
      "metadata": {
        "id": "kNDf61_LWIMC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqbXmtO14mLm"
      },
      "outputs": [],
      "source": [
        "model_ckpt=\"microsoft/MiniLM-L12-H384-uncased\"\n",
        "#ckpt is \"checkpoint\"\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGL8XHDJ6ihG"
      },
      "outputs": [],
      "source": [
        "# sample=\"I did not go running\"\n",
        "sample=emotion_dataset[\"train\"][\"text\"][0]\n",
        "\n",
        "encoded_input = tokenizer(sample, return_tensors='pt')\n",
        "\n",
        "# Print the token IDs (numbers)\n",
        "print(encoded_input['input_ids'][0])\n",
        "\n",
        "# Convert the token IDs back to tokens (subwords) and print them\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
        "print(tokens)\n",
        "\n",
        "# Print the original text for reference\n",
        "print(sample)\n",
        "encoded_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dvuZFpx73m2"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(examples):\n",
        "  return tokenizer(examples[\"text\"], truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81DcjxwC8UKC"
      },
      "outputs": [],
      "source": [
        "emotion_dataset=emotion_dataset.map(tokenize_text, batched=True)\n",
        "emotion_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with the imbalanced classes"
      ],
      "metadata": {
        "id": "WokBTdCOZSUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "urJjquyhW5Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EzqcakR8lbF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_weights=(1-(emotion_df[\"label\"].value_counts().sort_index()/len(emotion_df))).values\n",
        "print(class_weights)\n",
        "\n",
        "class_weights=torch.from_numpy(class_weights)\n",
        "print(class_weights)\n",
        "\n",
        "class_weights=class_weights.float()\n",
        "print(class_weights)\n",
        "\n",
        "#.to(\"cuda\") if GPU\n",
        "class_weights=class_weights#.to(\"cuda\")\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkTsQkHy_8wZ"
      },
      "outputs": [],
      "source": [
        "##See 12:57 minute mark of video\n",
        "emotion_dataset=emotion_dataset.rename_column(\"label\",\"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZb0c65eRryx"
      },
      "outputs": [],
      "source": [
        "emotion_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KSjgCF5DHTW"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Assuming `emotion_dataset[\"train\"]` is defined elsewhere and accessible\n",
        "logging_steps = len(emotion_dataset[\"train\"]) // batch_size\n",
        "output_dir = \"minilm-finetuned-emotion\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    # evaluation_strategy=\"epoch\", (seems to have been replaced in newer versions of transformers with next line)\n",
        "    eval_steps=logging_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    fp16=True,  # Changed to False for CPU compatibility\n",
        "    push_to_hub=True,  # Set based on your needs\n",
        "    report_to=\"none\",  # This disables integration with W&B\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The class Trainer has a method named compute_loss.\n",
        "But we are going to define a subclass of Trainer so that we can override compute_loss**"
      ],
      "metadata": {
        "id": "Jhw4PoFTcOnC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd5Zre_WblDU"
      },
      "outputs": [],
      "source": [
        "class WeightedLossTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):  # Add num_items_in_batch\n",
        "        # Move class_weights to the same device as the model\n",
        "        device = next(model.parameters()).device  # Get the device of the model\n",
        "        self.class_weights = class_weights.to(device)  # Move class_weights to the device\n",
        "\n",
        "        # Feed inputs to model and extract logits\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # Extract labels\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # Define loss function with class weights\n",
        "        loss_func = nn.CrossEntropyLoss(weight=self.class_weights)  # Use self.class_weights\n",
        "        # Compute loss\n",
        "        loss = loss_func(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17Nsf_2qfJd9"
      },
      "outputs": [],
      "source": [
        "model=AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
        "                                                      num_labels=6,\n",
        "                                                      id2label=id2label,\n",
        "                                                      label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDr9liQRh9f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    accuracy = accuracy_score(labels, preds)  # Calculate accuracy\n",
        "    return {\"f1\": f1, \"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6oYSrXiQDms"
      },
      "outputs": [],
      "source": [
        "trainer=WeightedLossTrainer(model=model,\n",
        "                          args=training_args,\n",
        "                          compute_metrics=compute_metrics,\n",
        "                          train_dataset=emotion_dataset[\"train\"],\n",
        "                          eval_dataset=emotion_dataset[\"validation\"],\n",
        "                          tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxH-MBAcZr4O"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(emotion_dataset[\"test\"])\n",
        "print(test_results)\n"
      ],
      "metadata": {
        "id": "ukoGVqiH_ETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "e8wdOeGyqcGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "mEpSIZefqlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt=\"alex-smith/minilm-finetuned-emotion\""
      ],
      "metadata": {
        "id": "gAjhsY4yqurA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe=pipeline(\"text-classification\",model=model_ckpt)"
      ],
      "metadata": {
        "id": "ck70Go5trAF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"I really dislike integration by parts if we have to do it twice!\")"
      ],
      "metadata": {
        "id": "wBEuRk9LrS0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select a sample text from the training split\n",
        "train_sample=random.randint(0, 16000)\n",
        "test_sample=random.randint(0,2000)\n",
        "\n",
        "train_text = emotion_dataset[\"train\"][\"text\"][train_sample]\n",
        "train_label=emotion_dataset[\"train\"][\"labels\"][train_sample]\n",
        "\n",
        "# Select a sample text from the testing split\n",
        "test_text = emotion_dataset[\"test\"][\"text\"][test_sample]\n",
        "test_label=emotion_dataset[\"test\"][\"labels\"][test_sample]\n",
        "\n",
        "# Classify the training text\n",
        "train_result = pipe(train_text)\n",
        "print(f\"Training text classification result:\\n {train_result}, actual label: {id2label[train_label]}\")\n",
        "print(f\"train text: {train_text}\")\n",
        "\n",
        "print(f\"\\n\")\n",
        "# Classify the testing text\n",
        "test_result = pipe(test_text)\n",
        "print(f\"Testing text classification result:\\n {test_result}, actual label: {id2label[test_label]}\")\n",
        "print(f\"test text: {test_text}\")"
      ],
      "metadata": {
        "id": "ztaZWUbhrrbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLxdYXd0rrjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mj9m3uHIrrqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2UP9yurhZ8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPvpJQpakDWvElmI8ojxAeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}